{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier Wilde vs Mistral7B-Instruct**\n",
    "\n",
    "In this notebook we are going to train a classifier for authorship atribution. The possible authors are Oscar Wilde or the baseline model Mistral7B-Instruct. The implementation of the classifier is based on the paper [BertAA: BERT fine-tuning for Authorship Attribution](https://aclanthology.org/2020.icon-main.16.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following lines to run in colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to install simpletransformers if you are running in colab\n",
    "# !pip install -U simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and models paths\n",
    "root_path = '.' # comment this line if you are running in colab\n",
    "root_path = './drive/MyDrive/DL-ENS' # uncomment this line if you are running in colab\n",
    "dir_data = f'{root_path}/data'\n",
    "models_path = f'{root_path}/models'\n",
    "wilde_texts_path = f'{dir_data}/wilde_complete.txt'\n",
    "mistral_gen_texts_list = f'{dir_data}/BaseModelCompletionsToTrainClassifier/dataset_mistral7B_gen_texts.json'\n",
    "authors_names = [\"Wilde\", \"Mistral7B-Instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the texts of an specific author\n",
    "def read_texts(path: str, label, len_to_read =None, max_length = 350):\n",
    "  \"\"\"\n",
    "  Read the texts of an specific author and return a dictionary with the texts and the labels\n",
    "  inputs:\n",
    "    path: str: path to the file with the texts\n",
    "    label: int: label to assign to the texts\n",
    "    len_to_read: int: number of texts to read from the author\n",
    "    max_length: int: max length of the texts to return\n",
    "  outputs:\n",
    "    dt: dict: dictionary with the texts and the labels\n",
    "  \"\"\"\n",
    "    text = ''\n",
    "    with open(path, 'r+') as fd:\n",
    "      text = fd.read()\n",
    "      if len_to_read != None:\n",
    "        text = text[:len_to_read]\n",
    "    text_splited = text.split()\n",
    "    dt = {'text': [], 'label': []}\n",
    "    for i in range(0,len(text_splited),max_length):\n",
    "      text = ' '.join(text_splited[i:min(i+max_length, len(text_splited))])\n",
    "      dt['text'].append(text)\n",
    "      dt['label'].append(label)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset for classification with both authors\n",
    "dt = {'text': [], 'label': []}\n",
    "for i,path in enumerate([wilde_texts_path, mistral_gen_texts_list]):\n",
    "  dt_i = read_texts(path,i)\n",
    "  dt['text'].extend(dt_i['text'])\n",
    "  dt['label'].extend(dt_i['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataset to DataFrame\n",
    "dt = DataFrame.from_dict(dt)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test\n",
    "dt_train, dt_test = train_test_split(dt, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of the labels in the train dataset\n",
    "dt_train.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of the labels in the test dataset\n",
    "dt_test.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for classifier and initial weights\n",
    "model_name = 'bert'\n",
    "model_weights =  'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model (take into the inbalance of the dataset by setting the weights of the classes to be the inverse of the frequency of the classes in the dataset)\n",
    "model = ClassificationModel(model_name, model_weights, num_labels=2, weight = [1 - sum(dt_train['label'])/len(dt_train['label']), sum(dt_train['label'])/len(dt_train['label'])], args={'reprocess_input_data': True, 'overwrite_output_dir': True,  'num_train_epochs' : 5}, use_cuda=True)\n",
    "model.train_model(dt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test dataset labels\n",
    "predictions, raw_out = model.predict(list(dt_test['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for the test dataset\n",
    "print(classification_report(dt_test['label'], predictions, target_names = authors_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classifier model\n",
    "model_save_name = 'BertAA_wilde_vs_mistral7B.pt'\n",
    "path = f\"{models_path}/{model_save_name}\"\n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
